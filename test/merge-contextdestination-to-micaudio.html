<html>
<head>
<meta charset="utf-8">
<script src="https://unpkg.com/@ffmpeg/ffmpeg@0.9.7/dist/ffmpeg.min.js"
crossorigin="anonymous">
</script>
</head>
<body>
Here
<script>
const { createFFmpeg } = FFmpeg;
const ffmpeg = createFFmpeg();
const sleep = msec => new Promise(resolve => setTimeout(resolve, msec));

const AudioContext = window.AudioContext || window.webkitAudioContext;

const types = [
             "video/webm",
             "audio/wav",
             "audio/mp3",
             "audio/ogg\;codecs=opus",
             "audio/webm",
             "video/webm\;codecs=vp8",
             "video/webm\;codecs=daala",
             "video/webm\;codecs=h264",
             "audio/webm\;codecs=opus",
             "video/mpeg"];

for (var i in types) {
  console.log( "Is " + types[i] + " supported? " 
  + (MediaRecorder.isTypeSupported(types[i]) ? "Maybe!" : "Nope :("));
}


// window.addEventListener('click', init);

const constraints = {
  audio: {
    autoGainControl: false, // default true
    echoCancellation: false, // default true
    noiseSuppression: false, // default true
    // volume: 0.5, // default undefined
    // channelCount: 4, // cannot be set (device dependent value)
  },
  video: false
}; 


const sources = [];
const recorders = [];
let audioCtx = null;
let outputAudioBuffers = [];

const stream2 = getWebAudioStream(); // PC audio
console.log(stream2.getTracks()[0].getSettings());
const stream = getMedia(constraints); // Mic

// microphone
async function getMedia(constraints) {
  let stream = null;

  try {
    stream = await navigator.mediaDevices.getUserMedia(constraints)  
    console.log('stream', stream);
    console.log(stream.getTracks()[0].getSettings());
    const mediaRecorder = new MediaRecorder(stream, {mimeType: 'video/webm'});
    console.log('mediaRecorder', mediaRecorder);
    const mediaRecorder2 = new MediaRecorder(stream2, {mimeType: 'video/webm'});
    console.log('mediaRecorder2', mediaRecorder2);
    recorders.push(mediaRecorder); recorders.push(mediaRecorder2);
  } catch (err) {console.log(err);}

    audioCtx.resume();
    sources[0].start(); sources[1].start();

    const chunks = [];
    const chunks2 = [];

    recorders.forEach ((recorder) => { 
      console.log('recorder start');
      recorder.start()
    });

    await sleep(30000);

    recorders.forEach ((recorder) => {
      console.log('recorder stop');
      recorder.stop();
    });
    sources.forEach ((source) => {source.stop();});

    recorders[0].onstop = function(e) {
      console.log('mediarecorder.onstop', e);
      console.log('chunks', chunks); // to see if mimeType defined
      download(chunks, 'micAudio.webm');
      webmToAudioBuffer(chunks);
    }

    recorders[0].ondataavailable = function(e) {
      chunks.push(e.data);
    }

    recorders[1].onstop = function(e) {
      console.log('mediarecorder.onstop', e);
      console.log('chunks2', chunks2);
      download(chunks2, 'PCAudio.webm');
      webmToAudioBuffer(chunks2);
    }

    recorders[1].ondataavailable = function(e) {
        chunks2.push(e.data);
    }

    await sleep(3000);
    console.log('outputAudioBuffers', outputAudioBuffers);

} // End getMedia()

function getWebAudioStream() {   

  console.log('getWebAudioStream');
  audioCtx = new AudioContext();
  
  const panNode0 = audioCtx.createStereoPanner();
    panNode0.pan.value = -1.0; // left
  const osc0 = audioCtx.createOscillator();
    osc0.frequency.setValueAtTime(220.0,audioCtx.currentTime); // lower A
    osc0.type = "sine"; // default (square, sawtooth, triangle, custom)
  const panNode1 = audioCtx.createStereoPanner();
    panNode1.pan.value = 1.0; // right
    const osc1 = audioCtx.createOscillator();
    osc1.frequency.setValueAtTime(220*Math.pow(2,7/12),audioCtx.currentTime); 
   // 5th note
    osc0.type = "sine";

  sources.push(osc0); sources.push(osc1);

  osc0.connect(panNode0); osc1.connect(panNode1);
  const gainNode = audioCtx.createGain();
    gainNode.gain.setValueAtTime(0.3, audioCtx.currentTime);

  panNode0.connect(gainNode); panNode1.connect(gainNode);

  const streamDestination = audioCtx.createMediaStreamDestination();
  gainNode.connect(streamDestination);
  gainNode.connect(audioCtx.destination);
  audioCtx.suspend();

  /*
  osc0.start(); osc0.stop(10); 
  osc1.start(); osc1.stop(20);
  */

  osc0.onended = function () {
    console.log('osc0 onended');
    isPlaying = false;
  }

  osc1.onended = function () {
    console.log('osc1 onended');
    isPlaying = false;
  }

  return streamDestination.stream;
} // end getWebAudioStream

function webmToAudioBuffer (recordedChunks) {

  const fileReader = new FileReader();
  const blob = new Blob(recordedChunks, { type: 'audio/webm' });
  
  fileReader.readAsArrayBuffer(blob);

  let retval = null;

  fileReader.onload = function() {
    let audioBuffer = null;
    audioCtx.decodeAudioData(fileReader.result, 
       function (audioBuffer) {
         console.log('decoded', audioBuffer);
         outputAudioBuffers.push(audioBuffer);
       }
    );
  }

  return retval;
}

function download(recordedChunks, name) {

  const blob = new Blob(recordedChunks, { type: 'audio/webm' });

  var url = URL.createObjectURL(blob);
  var a = document.createElement('a');
  document.body.appendChild(a);
  a.style = 'display: none';
  a.href = url;
  a.download = name;
  a.click();
  window.URL.revokeObjectURL(url);
} // download

async function toWav (inputBlob) {

  await ffmpeg.load();
  const name = 'input';
  ffmpeg.FS('WriteFile', name , inputBlob);
  const outputFile = 'output.wav';
  await ffmpeg.run('-i', name, outputFile);
  const data = ffmpeg.FS('readFile', outputFile); 
  return new Blob([data.buffer], { type: 'audio/wav'});

}
  
</script>
</body>
</html>
